from LLM_patch_generation.args_parser import parse_arguments_validator
from LLM_patch_generation.generator_utils import ask_LLM

def main():
    validator_prompt = ""

    # Setting directory containing correction patches
    args = parse_arguments_validator()
    patches_filepath = args.Patches_directory_filepath


    # Specifying targeted vulnerability 
    print("Identifying vulnerability...")
    with open(f'{patches_filepath}/deepseek-R1_details.txt', 'r') as f:
        for line in f:
            if line.startswith("Vulnerability:"):
                TARGET_VULNEARBILITY = line.split(":", 1)[1].strip()
                break


    # Storing all generated correction patches in a single variable
    print("Gathering generated correction patches...")
    MODELS = ['gemini-2.5-pro', 'gemini-2.5-flash', 'deepseek-V3.1', 'deepseek-R1']
    patches = {}

    for model in MODELS:
        with open(f'{patches_filepath}/{model}_patch.sh', 'r') as f:
            content = f.read()
            patches[model] = content
    
    GENERATED_CORRECTION_PATCHES = ""
    GENERATED_CORRECTION_PATCHES +=  f'''#########################################\n'''
    for model, patch in patches.items():
        GENERATED_CORRECTION_PATCHES +=  f'''CORRECTION PATCH GENERATED BY {model}:\n\n'''
        GENERATED_CORRECTION_PATCHES +=  f'''{patch}\n'''
        GENERATED_CORRECTION_PATCHES +=  f'''#########################################\n'''


    #response = ask_LLM('gpt-5.1', 'hello! how are you today?')

if __name__ == '__main__':
    main()